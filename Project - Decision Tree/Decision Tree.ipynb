{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "bf1b2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets    # Importing Datasets module from sklearn for Iris Dataset\n",
    "\n",
    "import pandas as pd    # Pandas library to handle iris dataset as Dataframe\n",
    "\n",
    "import numpy as np    # Numpy library to handle arrays and use numpy methods\n",
    "\n",
    "from sklearn.tree import export_graphviz   # export tree to graph\n",
    "\n",
    "import pydotplus    # pyplotplus library to export graph as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ce519b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()    # load_iris method to get iris dataset from sklearn\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data,columns=['SL','SW','PL','PW'])    # converting iris data into Dataframe and adding headers\n",
    "\n",
    "iris_df['target']=iris.target    # combining target values of iris dataset with Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "36ca6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# Seperating training and testing data for later checking accuracy of decision tree\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(iris.data,iris.target,random_state = 42)\n",
    "\n",
    "# combining target values of iris with features data for training data\n",
    "training_data = np.concatenate([X_train,Y_train.reshape(-1,1)],axis=1) \n",
    "\n",
    "# combining target values of iris with features data for testing data\n",
    "testing_data = np.concatenate([X_test,Y_test.reshape(-1,1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "57d0db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = iris.target_names   # setting target_names variable as target_names from iris dataset\n",
    "\n",
    "feature_names = list(iris.feature_names)    # setting feature_names variable as feature_names from iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "241ac3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL</th>\n",
       "      <th>SW</th>\n",
       "      <th>PL</th>\n",
       "      <th>PW</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SL          SW          PL          PW      target\n",
       "count  150.000000  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.057333    3.758000    1.199333    1.000000\n",
       "std      0.828066    0.435866    1.765298    0.762238    0.819232\n",
       "min      4.300000    2.000000    1.000000    0.100000    0.000000\n",
       "25%      5.100000    2.800000    1.600000    0.300000    0.000000\n",
       "50%      5.800000    3.000000    4.350000    1.300000    1.000000\n",
       "75%      6.400000    3.300000    5.100000    1.800000    2.000000\n",
       "max      7.900000    4.400000    6.900000    2.500000    2.000000"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe()    # Describing iris dataset to check if null values are present and get info about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "efbb5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "\n",
    "    This class just records a 'column number' (e.g., 0 for SL or sepal length in cm) and a\n",
    "    'column value' (e.g., 7.9). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question.\n",
    "    \"\"\"\n",
    "    def __init__(self,column,value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        # we are checking if value in example is less than or equal to value set in question\n",
    "        val = example[self.column]\n",
    "        return val <= self.value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        return \"Is %s <= %s?\"% (feature_names[int(self.column)], self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "7d15ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows,question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows,false_rows = [],[]\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows,false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7272bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    \"\"\"Calculate the Entropy for a list of rows.\n",
    "\n",
    "    Since target contains all columns. We need to retrive last column.\n",
    "    Using np.unique function we can get unique values in our target_col and count of those unique values\n",
    "    Then we can apply entropy formula for each unique result to get total entropy.\n",
    "    \"\"\"\n",
    "    target_col = np.array(target)[:,-1]\n",
    "    elements, counts = np.unique(target_col ,return_counts=True)\n",
    "    entropy= 0\n",
    "    for i in range(len(elements)):\n",
    "        entropy+= (-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "77b26e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left,right,parent):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    Difference between Entropy of parent node and Average entropy of child nodes.\n",
    "    \"\"\"\n",
    "    nl = len(left)\n",
    "    nr = len(right)\n",
    "    np = len(parent)\n",
    "    avgEntropy = (nl/np)*entropy(left) + (nr/np)*entropy(right)\n",
    "    return entropy(parent) - avgEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7e4112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    \n",
    "    best_gain = 0    # keep track of the best information gain\n",
    "    \n",
    "    best_question = None    # keep train of the feature / value that produced it\n",
    "    \n",
    "    n_features = len(rows[0])-1    # number of columns\n",
    "    \n",
    "    for col in range(n_features):   # for each feature\n",
    "        \n",
    "        values = set([row[col] for row in rows])  # unique values in the column\n",
    "        \n",
    "        for val in values:  # for each value\n",
    "            \n",
    "            question = Question(col,val)\n",
    "            \n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows,question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if(len(true_rows) == 0 or len(false_rows) ==0 ):\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, rows)\n",
    "\n",
    "            # We can use > instead of >= to compare best_gain and gain.\n",
    "            if(gain >= best_gain):\n",
    "                best_gain, best_question = gain, question\n",
    "        \n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d47d3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(rows):\n",
    "    np_rows = np.array(rows)\n",
    "    elements, counts = np.unique(np_rows[:,-1] ,return_counts=True)\n",
    "    predictions={}\n",
    "    for (e,c) in zip(elements,counts):\n",
    "        predictions[int(e)]=c\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "387b6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Setosa\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "    def __init__(self,rows):\n",
    "        self.predictions = predictions(rows)\n",
    "        self.rows = rows\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "0f0ad89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self,question,true_branch,false_branch,rows,gain):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.rows = rows\n",
    "        self.gain = gain\n",
    "        \n",
    "    def export(self,file_name):\n",
    "        dot_data = export_graphviz(self, out_file=None)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        graph.write_pdf(file_name+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f82db6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \"\"\"Builds the tree.\n",
    "\n",
    "    This uses recursion to get to Leaf Nodes where split is not possible and our gain turns to 0.\n",
    "    Once we get to Leaf Node for both true and false outputs we convert into branches\n",
    "    Then add it to Decision_Node Object to build a decision tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "    \n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    \n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "    \n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Decision_Node(question,true_branch,false_branch,rows,gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "61de5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node,feature_names,target_names, level=0):\n",
    "    \"\"\"Tree printing function\"\"\"\n",
    "    \n",
    "    print(\"\\nLevel\",level)\n",
    "    pred = predictions(node.rows)\n",
    "    for key in pred:\n",
    "        print( \"Count of\",target_names[key], \"=\", pred[key])\n",
    "    print(\"Current Entropy  is =\",entropy(node.rows))\n",
    "    \n",
    "    # Base case: we've reached a leaf\n",
    "    if( isinstance(node,Leaf) ):\n",
    "        print(\"Reached leaf Node\")\n",
    "        return\n",
    "    \n",
    "    col = int(node.question.column)\n",
    "    print(\"Splitting on feature\",feature_names[col],\"with gain ratio\",node.gain)\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print_tree(node.true_branch,feature_names,target_names,level+1)\n",
    "    \n",
    "    # Call this function recursively on the false branch\n",
    "    print_tree(node.false_branch,feature_names,target_names,level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "dfa5f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_data = [[1,1,1],\n",
    "           [0,1,1],\n",
    "           [1,0,1],\n",
    "           [0,0,0]]\n",
    "OR_feature_names = ['X1','X2']\n",
    "OR_target_names = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "852423de",
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_tree = build_tree(OR_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "460c46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0\n",
      "Count of 0 = 1\n",
      "Count of 1 = 3\n",
      "Current Entropy  is = 0.8112781244591328\n",
      "Splitting on feature X2 with gain ratio 0.31127812445913283\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 1\n",
      "Count of 1 = 1\n",
      "Current Entropy  is = 1.0\n",
      "Splitting on feature X1 with gain ratio 1.0\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 1 = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 1 = 2\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "print_tree(OR_tree,OR_feature_names,OR_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "1adda3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_graph(obj,file_name,feature_names):\n",
    "        dot_data = export_graphviz(obj, out_file=None,feature_names=feature_names)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        graph.write_pdf(file_name+\".pdf\")\n",
    "# export_graph(OR_tree,\"OR_Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "f03d3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Builiding tree of training data of iris dataset.\n",
    "# my_tree = build_tree(training_data) \n",
    "\n",
    "# To use whole iris dataset to build tree pass `iris_df.values` instead of `training_data` OR vice-versa\n",
    "iris_tree = build_tree(iris_df.values) \n",
    "\n",
    "target_names = iris.target_names   # setting target_names variable as target_names from iris dataset\n",
    "\n",
    "feature_names = list(iris.feature_names)    # setting feature_names variable as feature_names from iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e4ad39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0\n",
      "Count of setosa = 50\n",
      "Count of versicolor = 50\n",
      "Count of virginica = 50\n",
      "Current Entropy  is = 1.584962500721156\n",
      "Splitting on feature petal width (cm) with gain ratio 0.9182958340544894\n",
      "\n",
      "Level 1\n",
      "Count of setosa = 50\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of versicolor = 50\n",
      "Count of virginica = 50\n",
      "Current Entropy  is = 1.0\n",
      "Splitting on feature petal width (cm) with gain ratio 0.6901603707546748\n",
      "\n",
      "Level 2\n",
      "Count of versicolor = 49\n",
      "Count of virginica = 5\n",
      "Current Entropy  is = 0.44506485705083865\n",
      "Splitting on feature petal length (cm) with gain ratio 0.21317043093799645\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 47\n",
      "Count of virginica = 1\n",
      "Current Entropy  is = 0.1460942501201363\n",
      "Splitting on feature petal width (cm) with gain ratio 0.1460942501201363\n",
      "\n",
      "Level 4\n",
      "Count of versicolor = 47\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of virginica = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 2\n",
      "Count of virginica = 4\n",
      "Current Entropy  is = 0.9182958340544896\n",
      "Splitting on feature petal width (cm) with gain ratio 0.4591479170272448\n",
      "\n",
      "Level 4\n",
      "Count of virginica = 3\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of versicolor = 2\n",
      "Count of virginica = 1\n",
      "Current Entropy  is = 0.9182958340544896\n",
      "Splitting on feature petal length (cm) with gain ratio 0.9182958340544896\n",
      "\n",
      "Level 5\n",
      "Count of versicolor = 2\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of virginica = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of versicolor = 1\n",
      "Count of virginica = 45\n",
      "Current Entropy  is = 0.15109697051711368\n",
      "Splitting on feature petal length (cm) with gain ratio 0.09120811177442958\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 1\n",
      "Count of virginica = 2\n",
      "Current Entropy  is = 0.9182958340544896\n",
      "Splitting on feature sepal width (cm) with gain ratio 0.9182958340544896\n",
      "\n",
      "Level 4\n",
      "Count of virginica = 2\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of versicolor = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of virginica = 43\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "print_tree(iris_tree,feature_names,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752468a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41326044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3ee2f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7bf78e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_clf = DecisionTreeClassifier(random_state=0,criterion='entropy')\n",
    "train = np.array(OR_data)\n",
    "OR_clf.fit(train[:,:-1],train[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "90704003",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graph(clf,\"OR_tree\",OR_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ac240591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_clf = DecisionTreeClassifier(random_state=0,criterion='entropy')\n",
    "iris_clf.fit(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "6ed4312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graph(iris_clf,\"iris_tree\",feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc905351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
